{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ct4zxZwtVvre"},"outputs":[],"source":["from torchsummary import summary"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"KwEA6bO6WADa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# BGRU"],"metadata":{"id":"pjj9jWiQ4CpL"}},{"cell_type":"code","source":["class StackedBiGRUNet(nn.Module):\n","    def __init__(self, input_size, hidden_sizes, output_size):\n","        super(StackedBiGRUNet, self).__init__()\n","        self.num_layers = len(hidden_sizes)\n","        self.hidden_sizes = hidden_sizes\n","        self.gru_layers = nn.ModuleList()\n","\n","        # Create bidirectional GRU layers\n","        for i in range(self.num_layers):\n","            if i == 0:\n","                input_dim = input_size\n","            else:\n","                input_dim = self.hidden_sizes[i-1] * 2  # Multiply by 2 for bidirectional\n","\n","            self.gru_layers.append(nn.GRU(input_dim, self.hidden_sizes[i], batch_first=True, bidirectional=True))\n","\n","        # Final fully connected layer\n","        self.final_fc = nn.Linear(self.hidden_sizes[-1] * 2, output_size)\n","\n","    def forward(self, x):\n","\n","        for i in range(self.num_layers):\n","            # Initialize hidden state with zeros\n","            h0 = torch.zeros(2, x.size(0), self.hidden_sizes[i]).to(x.device)  # *2 for bidirectional\n","\n","            # Forward propagate GRU\n","            out, _ = self.gru_layers[i](x, h0)\n","\n","            # # Decode the hidden state of the last time step\n","            # out = self.fc_layers[i](out[:, -1, :])\n","            x = out\n","\n","        # Extract the output of the last time step of the last layer\n","        out = out[:, -1, :]\n","\n","        # Final fully connected layer\n","        out = self.final_fc(out)\n","        return out"],"metadata":{"id":"OdRGuih-bqXZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TheActualGRU(nn.Module):\n","\n","  def __init__(self):\n","    super(TheActualGRU, self).__init__()\n","\n","    self.bgru_1 = nn.GRU(300, 300, batch_first = True, bidirectional = True) # output: x: (N,L,2∗H_out), h_n: (2∗num_layers,N,H_out​)\n","    self.bgru_2 = nn.GRU(600, 200, batch_first = True, bidirectional = True)\n","    self.dropout_1 = nn.Dropout(p = 0.2)\n","    self.bgru_3 = nn.GRU(400, 50, batch_first = True, bidirectional = True)\n","    self.fc1 = nn.Linear(100, 50)\n","    self.dropout_2 = nn.Dropout(p = 0.2)\n","    self.fc2 = nn.Linear(50, 3)\n","\n","  def forward(self, x):\n","    # h0 = torch.zeros(2, x.size(0), 300).to(x.device) # defaults to zero if not provided\n","\n","    x, _ = self.bgru_1(x)\n","    x, _ = self.bgru_2(x)\n","    x = self.dropout_1(x)\n","    x, _ = self.bgru_3(x)\n","    x = x[:, -1, :]\n","    x = self.fc1(x)\n","    x = self.dropout_2(x)\n","    x = self.fc2(x)\n","\n","    return F.softmax(x, dim=1)"],"metadata":{"id":"8vgmnmT0gDvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary(TheActualGRU(), (5, 300))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rDgyIkjI0X2V","executionInfo":{"status":"ok","timestamp":1713018448498,"user_tz":-210,"elapsed":4,"user":{"displayName":"Parham Moonesi","userId":"12209666602904044137"}},"outputId":"a0a9db93-e953-4c60-b8fc-87c47cf303a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","               GRU-1  [[-1, 5, 600], [-1, 2, 300]]               0\n","               GRU-2  [[-1, 5, 400], [-1, 2, 200]]               0\n","           Dropout-3               [-1, 5, 400]               0\n","               GRU-4  [[-1, 5, 100], [-1, 2, 50]]               0\n","            Linear-5                   [-1, 50]           5,050\n","           Dropout-6                   [-1, 50]               0\n","            Linear-7                    [-1, 3]             153\n","================================================================\n","Total params: 5,203\n","Trainable params: 5,203\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 20.20\n","Params size (MB): 0.02\n","Estimated Total Size (MB): 20.23\n","----------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"BDsCOZxI4FWd"}},{"cell_type":"code","source":["class ConvBlock(nn.Module):\n","\n","  def __init__(self):\n","    super(ConvBlock, self).__init__()\n","\n","    self.conv_0_1 = nn.Conv3d(1, 15, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding='same')\n","    self.bn_0 = nn.BatchNorm3d(15)\n","    self.conv_0_p = nn.Conv3d(15, 15, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n","\n","    self.conv_1_1 = nn.Conv3d(15, 15, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding='same')\n","    self.bn_1 = nn.BatchNorm3d(15)\n","    self.conv_1_2 = nn.Conv3d(15, 15, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding='same')\n","\n","    # merge1: layer 0 and layer 1\n","\n","    self.bn_2_1 = nn.BatchNorm3d(30)\n","    self.conv_2_1 = nn.Conv3d(30, 25, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n","    self.bn_2_2 = nn.BatchNorm3d(25)\n","    self.conv_2_2 = nn.Conv3d(25, 25, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding='same')\n","    self.conv_2_cut = nn.Conv3d(30, 15, kernel_size=(2, 2, 2), stride=(2, 2, 2)) # input from merge 1\n","\n","    # merge2: layer2 and the cut2\n","\n","    self.bn_3_1 = nn.BatchNorm3d(40)\n","    self.conv_3_1 = nn.Conv3d(40, 35, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n","    self.bn_3_2 = nn.BatchNorm3d(35)\n","    self.conv_3_2 = nn.Conv3d(35, 35, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding='same')\n","    self.conv_3_cut = nn.Conv3d(40, 25, kernel_size=(2, 2, 2), stride=(2, 2, 2)) # input from merge 2\n","\n","    # merge3: layer3 and the cut3\n","\n","    self.bn_4 = nn.BatchNorm3d(60)\n","    self.conv_4_1 = nn.Conv3d(60, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding='valid')\n","    self.conv_4_2 = nn.Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding='valid')\n","\n","\n","  def forward(self, x):\n","\n","    x = self.conv_0_1(x)\n","    x = F.relu(self.bn_0(x))\n","    x1 = self.conv_0_p(x)\n","\n","    x = self.conv_1_1(x1)\n","    x = F.dropout(F.relu(self.bn_1(x)), p=0.2) #?\n","    x = self.conv_1_2(x)\n","\n","    x2 = torch.cat((x1, x), dim=1) # merge_1\n","\n","    x = F.relu(self.bn_2_1(x2))\n","    x = self.conv_2_1(x)\n","    x = F.relu(self.bn_2_2(F.dropout(x, p=0.2)))\n","    x = self.conv_2_2(x)\n","\n","    xc2 = self.conv_2_cut(x2)\n","    x3 = torch.cat((x, xc2), dim=1) # merge_2\n","\n","    x = F.relu(self.bn_3_1(x3))\n","    x = self.conv_3_1(x)\n","    x = F.relu(self.bn_3_2(F.dropout(x, p=0.2)))\n","    x = self.conv_3_2(x)\n","\n","    xc3 = self.conv_3_cut(x3)\n","    x4 = torch.cat((x, xc3), dim=1) # merge_3\n","\n","    x = F.relu(self.bn_4(x4))\n","    x = self.conv_4_1(x)\n","    x = self.conv_4_2(x)\n","\n","    return x\n"],"metadata":{"id":"2EY4t7ll4XJG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary(ConvBlock(), (1, 50, 42, 42))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xnf8dwcIO6ZT","executionInfo":{"status":"ok","timestamp":1713026643228,"user_tz":-210,"elapsed":495,"user":{"displayName":"Parham Moonesi","userId":"12209666602904044137"}},"outputId":"207fa0d8-0b30-4830-f347-417f8f329963"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv3d-1       [-1, 15, 50, 42, 42]             420\n","       BatchNorm3d-2       [-1, 15, 50, 42, 42]              30\n","            Conv3d-3       [-1, 15, 25, 21, 21]           1,815\n","            Conv3d-4       [-1, 15, 25, 21, 21]           6,090\n","       BatchNorm3d-5       [-1, 15, 25, 21, 21]              30\n","            Conv3d-6       [-1, 15, 25, 21, 21]           6,090\n","       BatchNorm3d-7       [-1, 30, 25, 21, 21]              60\n","            Conv3d-8       [-1, 25, 12, 10, 10]           6,025\n","       BatchNorm3d-9       [-1, 25, 12, 10, 10]              50\n","           Conv3d-10       [-1, 25, 12, 10, 10]          16,900\n","           Conv3d-11       [-1, 15, 12, 10, 10]           3,615\n","      BatchNorm3d-12       [-1, 40, 12, 10, 10]              80\n","           Conv3d-13          [-1, 35, 6, 5, 5]          11,235\n","      BatchNorm3d-14          [-1, 35, 6, 5, 5]              70\n","           Conv3d-15          [-1, 35, 6, 5, 5]          33,110\n","           Conv3d-16          [-1, 25, 6, 5, 5]           8,025\n","      BatchNorm3d-17          [-1, 60, 6, 5, 5]             120\n","           Conv3d-18          [-1, 30, 4, 3, 3]          48,630\n","           Conv3d-19          [-1, 30, 2, 1, 1]          24,330\n","================================================================\n","Total params: 166,725\n","Trainable params: 166,725\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.34\n","Forward/backward pass size (MB): 29.17\n","Params size (MB): 0.64\n","Estimated Total Size (MB): 30.15\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["class ActualCNN(nn.Module):\n","\n","  def __init__(self):\n","    super(ActualCNN, self).__init__()\n","\n","    self.conv_block = ConvBlock()\n","\n","    self.flatten = nn.Flatten()\n","\n","    self.fc1 = nn.Linear(60, 300)\n","    self.fc2 = nn.Linear(300, 50)\n","    self.fc3 = nn.Linear(50, 3)\n","\n","  def forward(self, x):\n","\n","    x = self.conv_block(x)\n","\n","    x = self.flatten(x)\n","\n","    x = F.relu(F.dropout(self.fc1(x), p=0.2))\n","    x = F.relu(self.fc2(x))\n","    x = self.fc3(x)\n","\n","    return F.softmax(x, dim=1)"],"metadata":{"id":"3fUkzWQ2Wmcj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary(ActualCNN(), (1, 50, 42, 42))"],"metadata":{"id":"Wbr3huPaYENT","executionInfo":{"status":"ok","timestamp":1713027176985,"user_tz":-210,"elapsed":12,"user":{"displayName":"Parham Moonesi","userId":"12209666602904044137"}},"outputId":"2a194755-34dc-4dfd-d8fe-117e3529830e","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv3d-1       [-1, 15, 50, 42, 42]             420\n","       BatchNorm3d-2       [-1, 15, 50, 42, 42]              30\n","            Conv3d-3       [-1, 15, 25, 21, 21]           1,815\n","            Conv3d-4       [-1, 15, 25, 21, 21]           6,090\n","       BatchNorm3d-5       [-1, 15, 25, 21, 21]              30\n","            Conv3d-6       [-1, 15, 25, 21, 21]           6,090\n","       BatchNorm3d-7       [-1, 30, 25, 21, 21]              60\n","            Conv3d-8       [-1, 25, 12, 10, 10]           6,025\n","       BatchNorm3d-9       [-1, 25, 12, 10, 10]              50\n","           Conv3d-10       [-1, 25, 12, 10, 10]          16,900\n","           Conv3d-11       [-1, 15, 12, 10, 10]           3,615\n","      BatchNorm3d-12       [-1, 40, 12, 10, 10]              80\n","           Conv3d-13          [-1, 35, 6, 5, 5]          11,235\n","      BatchNorm3d-14          [-1, 35, 6, 5, 5]              70\n","           Conv3d-15          [-1, 35, 6, 5, 5]          33,110\n","           Conv3d-16          [-1, 25, 6, 5, 5]           8,025\n","      BatchNorm3d-17          [-1, 60, 6, 5, 5]             120\n","           Conv3d-18          [-1, 30, 4, 3, 3]          48,630\n","           Conv3d-19          [-1, 30, 2, 1, 1]          24,330\n","        ConvBlock-20          [-1, 30, 2, 1, 1]               0\n","          Flatten-21                   [-1, 60]               0\n","           Linear-22                  [-1, 300]          18,300\n","           Linear-23                   [-1, 50]          15,050\n","           Linear-24                    [-1, 3]             153\n","================================================================\n","Total params: 200,228\n","Trainable params: 200,228\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.34\n","Forward/backward pass size (MB): 29.18\n","Params size (MB): 0.76\n","Estimated Total Size (MB): 30.28\n","----------------------------------------------------------------\n"]}]}]}